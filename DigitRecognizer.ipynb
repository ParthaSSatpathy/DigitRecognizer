{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import All the Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "path = \"C:/Users/parth/Desktop/Git/Projects/DigitRecognizer/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the Train file\n",
    "train_df = pd.read_csv(path+'train.csv')\n",
    "print(train_df.info())\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column of the Train Data contains the actual numbers and the rest of the columns contain the pixels of the picture. There are 784 columns of pixels which is the flattened array of the 28x28 image data.\n",
    "\n",
    "Let's extract the image data and image labels from the Train Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images = train_df.iloc[:,1:].values\n",
    "train_images = train_images.astype(np.float)\n",
    "train_labels = train_df[[0]].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row is an image. Let's extract the image of first 8 pictures and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  [1, 0, 1, 4, 0, 0, 7, 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAADkCAYAAABXPKW7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bddce62ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Labels: ',[i for i in train_labels[:8]])\n",
    "\n",
    "for i in range(8):\n",
    "    image = train_images[i].reshape(28,28)\n",
    "    #print(image)\n",
    "    plt.subplot(2,4,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image,cmap=cm.binary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bring the image pixel data from range of 0 to 255 -> 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_images = np.multiply(train_images, 1.0 / 255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use OneHot Encoder to convert the Labels.\n",
    "\n",
    "0->[1 0 0 0 0 0 0 0 0 0]\n",
    "\n",
    "1->[0 1 0 0 0 0 0 0 0 0]\n",
    "\n",
    "....\n",
    "\n",
    "9->[0 0 0 0 0 0 0 0 0 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels(42000,10)\n",
      "labels[0] => [0 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "labels = dense_to_one_hot(train_labels, 10)\n",
    "labels = labels.astype(np.uint8)\n",
    "\n",
    "print('labels({0[0]},{0[1]})'.format(labels.shape))\n",
    "print ('labels[{0}] => {1}'.format(0,labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 784)\n",
      "(33600, 10)\n",
      "(8400, 784)\n",
      "(8400, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(train_images, labels, test_size=0.2,random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Weights and Biases function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight Initialization\n",
    "\n",
    "To create this model, we're going to need to create a lot of weights and biases. One should generally initialize weights with a small amount of noise for symmetry breaking, and to prevent 0 gradients. Since we're using ReLU neurons, it is also good practice to initialize them with a slightly positive initial bias to avoid \"dead neurons\". Instead of doing this repeatedly while we build the model, let's create two handy functions to do it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Convolution and Max Pooling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv2d:\n",
    "Computes a 2-D convolution given 4-D input and filter tensors.\n",
    "\n",
    "Given an input tensor of shape [batch, in_height, in_width, in_channels] and a filter / kernel \n",
    "tensor of shape [filter_height, filter_width, in_channels, out_channels], this op performs the following:\n",
    "\n",
    "Flattens the filter to a 2-D matrix with shape [filter_height * filter_width * in_channels, output_channels].\n",
    "Extracts image patches from the input tensor to form a virtual tensor of \n",
    "shape [batch, out_height, out_width, filter_height * filter_width * in_channels].\n",
    "For each patch, right-multiplies the filter matrix and the image patch vector.\n",
    "\n",
    "max_pool_2x:\n",
    "Performs the max pooling on the input.\n",
    "\n",
    "Args:\n",
    "\n",
    "value: A 4-D Tensor with shape [batch, height, width, channels] and type tf.float32.\n",
    "ksize: A list of ints that has length >= 4. The size of the window for each dimension of the input tensor.\n",
    "strides: A list of ints that has length >= 4. The stride of the sliding window for each dimension of the input tensor.\n",
    "padding: A string, either 'VALID' or 'SAME'. The padding algorithm. \n",
    "data_format: A string. 'NHWC' and 'NCHW' are supported.\n",
    "name: Optional name for the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input & output of NN\n",
    "# images\n",
    "x = tf.placeholder('float', shape=[None, 784])\n",
    "# labels\n",
    "y_ = tf.placeholder('float', shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x isn't a specific value. It's a placeholder, a value that we'll input when we ask TensorFlow to run a computation. We want to be able to input any number of MNIST images, each flattened into a 784-dimensional vector. We represent this as a 2-D tensor of floating-point numbers, with a shape [None, 784]. (Here None means that a dimension can be of any length.)\n",
    "\n",
    "y_ is a new placeholder to input the correct answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Convolution Layer\n",
    "\n",
    "It will consist of convolution, followed by max pooling. The convolution will compute 32 features for each 5x5 patch. Its weight tensor will have a shape of [5, 5, 1, 32]. The first two dimensions are the patch size, the next is the number of input channels, and the last is the number of output channels. We will also have a bias vector with a component for each output channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5,5,1,32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the layer, we first reshape x to a 4d tensor, with the second and third dimensions corresponding to image width and height, and the final dimension corresponding to the number of color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then convolve x_image with the weight tensor, add the bias, apply the ReLU function, and finally max pool. The max_pool_2x2 method will reduce the image size to 14x14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1)\n",
    "h_pool = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare for visualization\n",
    "# display 32 fetures in 4 by 8 grid\n",
    "layer1 = tf.reshape(h_conv1, (-1, 28, 28, 4 ,8))  \n",
    "\n",
    "# reorder so the channels are in the first dimension, x and y follow.\n",
    "layer1 = tf.transpose(layer1, (0, 3, 1, 4,2))\n",
    "\n",
    "layer1 = tf.reshape(layer1, (-1, 28*4, 28*8)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Convolutional Layer\n",
    "\n",
    "In order to build a deep network, we stack several layers of this type. The second layer will have 64 features for each 5x5 patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool,W_conv2)+b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Prepare for visualization\n",
    "# display 64 fetures in 4 by 16 grid\n",
    "layer2 = tf.reshape(h_conv2, (-1, 14, 14, 4 ,16))  \n",
    "\n",
    "# reorder so the channels are in the first dimension, x and y follow.\n",
    "layer2 = tf.transpose(layer2, (0, 3, 1, 4,2))\n",
    "\n",
    "layer2 = tf.reshape(layer2, (-1, 14*4, 14*16)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Densely Connected Layer\n",
    "\n",
    "Now that the image size has been reduced to 7x7, we add a fully-connected layer with 1024 neurons to allow processing on the entire image. We reshape the tensor from the pooling layer into a batch of vectors, multiply by a weight matrix, add a bias, and apply a ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7*7*64,1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout\n",
    "\n",
    "To reduce overfitting, we will apply dropout before the readout layer. We create a placeholder for the probability that a neuron's output is kept during dropout. This allows us to turn dropout on during training, and turn it off during testing. TensorFlow's tf.nn.dropout op automatically handles scaling neuron outputs in addition to masking them, so dropout just works without any additional scaling.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add SoftMax Regression Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2= weight_variable([1024,10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss can be found using Cross Entropy\n",
    "Optimization will be done using ADAMOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = tf.argmax(y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# A mildly random version....simply pick one of the (consecutive) slices of size \"size\"\n",
    "from random import randint\n",
    "\n",
    "# This is used below, for simplicity and for faster convergence ;)\n",
    "def random_batch(data,labels,size):\n",
    "    value = math.floor(len(data) / size)    \n",
    "    intervall = randint(0,value-1)\n",
    "    return data[intervall*size:intervall*(size+1)],labels[intervall*size:intervall*(size+1)]\n",
    "\n",
    "# print(random_batch(trainfv,ohtrainLabelsNdarray,3))\n",
    "\n",
    "from random import sample\n",
    "\n",
    "# of course, this could be done in a myriad of (better) ways...\n",
    "# This \"random\" picking (not subarray-wise, as above) leads to far slower\n",
    "# learning - which justifies the assumption that \"similar\" digits (from\n",
    "# the same writer perhaps) which we want too learn to differentiate, \n",
    "# often are close together in the original data, making it useful to learn\n",
    "# them together in batches\n",
    "def really_random_batch(data,labels,size):\n",
    "    res_data = np.empty((size,784))\n",
    "    res_label = np.empty((size,10))\n",
    "    \n",
    "    l = len(data)\n",
    "    s = sample(range(l), size)\n",
    "    \n",
    "    for i in range(size):\n",
    "        res_data[i] = data[i]\n",
    "        res_label[i] = labels[i]\n",
    "        \n",
    "    return np.array(res_data),np.array(res_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Training (go higher for better results, e.g. 1500)\\nfor i in range(20000):\\n    batch_xs, batch_ys = random_batch(X_train,Y_train,50)\\n    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\\n    if not(i % 50): \\n        print(i)\\n\\n# Test our prediction \\ncorrect_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\\nprint(\"\\nAccuracy of the current model: \",sess.run(accuracy, feed_dict={x: trainfv[0:10000],\\n                                   y_: ohtrainLabelsNdarray[0:10000]}))\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Training (go higher for better results, e.g. 1500)\n",
    "for i in range(20000):\n",
    "    batch_xs, batch_ys = random_batch(X_train,Y_train,50)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    if not(i % 50): \n",
    "        print(i)\n",
    "\n",
    "# Test our prediction \n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"\\nAccuracy of the current model: \",sess.run(accuracy, feed_dict={x: trainfv[0:10000],\n",
    "                                   y_: ohtrainLabelsNdarray[0:10000]}))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.0608696\n",
      "step 1000, training accuracy 0.927273\n",
      "step 2000, training accuracy 0.968254\n",
      "step 3000, training accuracy 0.994911\n",
      "step 4000, training accuracy 1\n",
      "step 5000, training accuracy 0.996743\n",
      "step 6000, training accuracy 0.990385\n",
      "step 7000, training accuracy 1\n",
      "step 8000, training accuracy 1\n",
      "step 9000, training accuracy 1\n",
      "test accuracy 0.997619\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    batch_xs, batch_ys = random_batch(train_images,labels,100)\n",
    "    if i%1000 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch_xs, y_: batch_ys, keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x:batch_xs, y_: batch_ys, keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: X_val, y_: Y_val, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_images(28000,784)\n"
     ]
    }
   ],
   "source": [
    "# read test data from CSV file \n",
    "test_images = pd.read_csv(path+'test.csv').values\n",
    "test_images = test_images.astype(np.float)\n",
    "\n",
    "# convert from [0:255] => [0.0:1.0]\n",
    "test_images = np.multiply(test_images, 1.0 / 255.0)\n",
    "\n",
    "print('test_images({0[0]},{0[1]})'.format(test_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "predicted_lables = np.zeros(test_images.shape[0])\n",
    "for i in range(0,test_images.shape[0]//BATCH_SIZE):\n",
    "    predicted_lables[i*BATCH_SIZE : (i+1)*BATCH_SIZE] = predict.eval(feed_dict={x: test_images[i*BATCH_SIZE : (i+1)*BATCH_SIZE], keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_lables(28000)\n"
     ]
    }
   ],
   "source": [
    "print('predicted_lables({0})'.format(len(predicted_lables)))\n",
    "\n",
    "# output test image and prediction\n",
    "#display(test_images[IMAGE_TO_DISPLAY])\n",
    "#print ('predicted_lables[{0}] => {1}'.format(IMAGE_TO_DISPLAY,predicted_lables[IMAGE_TO_DISPLAY]))\n",
    "\n",
    "# save results\n",
    "np.savetxt(path+'submission_softmax2.csv', \n",
    "           np.c_[range(1,len(test_images)+1),predicted_lables], \n",
    "           delimiter=',', \n",
    "           header = 'ImageId,Label', \n",
    "           comments = '', \n",
    "           fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
